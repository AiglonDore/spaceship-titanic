{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a8df27",
   "metadata": {},
   "source": [
    "# Spaceship titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfdb9b",
   "metadata": {},
   "source": [
    "# 1. Import Libraries/ Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sns.set(rc={'figure.figsize':(6, 4)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.color_palette(\"flare\")\n",
    "sns.set_palette(sns.color_palette(\"flare\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792d14c",
   "metadata": {},
   "source": [
    "# 2. EDA (Exploratory Data Analysis) and Data Preprocessing\n",
    "\n",
    "\n",
    "The goal of EDA is to understand the main characteristics of the data and identify any patterns, outliers, or other features of the data that are important to know before building a model or making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a3538",
   "metadata": {},
   "source": [
    "### Observations in Train Data\n",
    "It's a first step in EDA. It is useful for understanding the main characteristics of the data and identifying any patterns, outliers, or other features of the data.\n",
    "\n",
    "- There are total of 14 columns and 8693 rows in train data.\n",
    "- Train data contains 119378 observation with 2324 missing values.\n",
    "- All 12 feature columns have missing values in them with CryoSleep having highest missing values (217) \n",
    "- Transported is the target variable which is only available in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc99802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of train data: {train_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ac794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows in train data: {train_data.shape[0]}')\n",
    "print(f'Number of columns in train data: {train_data.shape[1]}')\n",
    "print(f'Number of values in train data: {train_data.count().sum()}')\n",
    "print(f'Number missing values in train data: {sum(train_data.isna().sum())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade79955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.isna().sum().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88763fc",
   "metadata": {},
   "source": [
    "The basic statistics for each variables which contain information on count, mean, standard deviation, minimum, 1st quartile, median, 3rd quartile and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b086e",
   "metadata": {},
   "source": [
    "The pandas-profiling library allows you to generate a profile report that allows you to obtain the types of all the columns and to access statistical details at the quantile level, descriptions, histograms, and the most frequent and exterm values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d84ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "ProfileReport(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee957fa0",
   "metadata": {},
   "source": [
    "### Observations in Test Data\n",
    "- There are total of 13 columns and 4277 rows in test data.\n",
    "- Test data contains 54484 observation with 1117 missing values.\n",
    "- All 12 feature columns have missing values in them with FoodCourt having highest missing values (106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4489d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of test data: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89486f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows in test data: {test_data.shape[0]}')\n",
    "print(f'Number of columns in test data: {test_data.shape[1]}')\n",
    "print(f'Number of values in train data: {test_data.count().sum()}')\n",
    "print(f'Number of rows with missing values  in test data: {sum(test_data.isna().sum())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((test_data.isna().sum().sort_values(ascending = False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ee9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of test data \n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6e760",
   "metadata": {},
   "source": [
    "### Visualization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bfae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc =LabelEncoder()\n",
    "train_data['Transported'] = enc.fit_transform(train_data['Transported'])\n",
    "sns.countplot(data=train_data,x=train_data.Transported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_data, x='Destination', hue='Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a342903",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_data, x='HomePlanet', hue='Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=train_data, x='HomePlanet', hue='Destination')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42892325",
   "metadata": {},
   "source": [
    "### Visualization of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842675eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Missingno to Diagnose Data Sparsity\n",
    "\n",
    "msno.matrix(train_data).set_title(\"Train set\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4466954",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(test_data).set_title(\"Test set\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c666a84",
   "metadata": {},
   "source": [
    "### Correlation matrix\n",
    "\n",
    "Darker colors indicate a stronger positive correlation, while lighter colors indicate a weaker positive correlation or a negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_data.corr(), annot = True, linewidths= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e9748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5, figsize=(25, 10))\n",
    "corr = train_data.apply(lambda x: pd.factorize(x)[0]).corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "ax = sns.heatmap(corr, mask=mask, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, linewidths=.2, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0ce0f",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering\n",
    "Feature engineering is the process of using domain knowledge to extract features from raw data that can be used to train machine learning models. It involves transforming raw data into a format that can be easily understood by the model, such as converting text to numerical values. The goal of feature engineering is to create a set of features that are most informative and relevant for the task at hand, which can improve the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23739c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Name', axis=1, inplace=True)\n",
    "test_data.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Transported'].replace(False, 0, inplace=True)\n",
    "train_data['Transported'].replace(True, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['deck','num', 'side']] = train_data['Cabin'].str.split('/', expand=True)\n",
    "test_data[['deck','num', 'side']] = test_data['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "train_data.drop('Cabin', axis=1, inplace=True)\n",
    "test_data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_sum = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "train_data['total_spent'] = train_data[col_to_sum].sum(axis=1)\n",
    "test_data['total_spent'] = test_data[col_to_sum].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b485d",
   "metadata": {},
   "source": [
    "###  Imputing Missing Values\n",
    "\n",
    "\n",
    "We are using Simple Imputer to fill the na values with the specified strategy.\n",
    "\n",
    "For ['CryoSleep', 'VIP', 'HomePlanet', 'Destination', 'Cabin'] we use the strategy most_frequent as it is categorical data.\n",
    "\n",
    "For ['Age','RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'] we use the strategy median as it is numeric data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [col for col in train_data.columns if train_data[col].dtype == 'object' or train_data[col].dtype == 'category']\n",
    "numeric_cols = [col for col in train_data.columns if train_data[col].dtype == 'float64']\n",
    "\n",
    "print(f'Categorical cols -- {categorical_cols}')\n",
    "print(f'Numeric cols -- {numeric_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fa67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[categorical_cols] = train_data[categorical_cols].astype('category')\n",
    "test_data[categorical_cols] = test_data[categorical_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f30d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "oc = OrdinalEncoder()\n",
    "data_for_encode = pd.concat([train_data, test_data])\n",
    "data_for_encode[categorical_cols] = data_for_encode[categorical_cols].astype('category')\n",
    "data_for_encode[categorical_cols] = oc.fit_transform(data_for_encode[categorical_cols])\n",
    "\n",
    "del train_data, test_data\n",
    "\n",
    "train_data = data_for_encode.iloc[:8693, :]\n",
    "test_data = data_for_encode.iloc[8693: , :]\n",
    "\n",
    "del data_for_encode\n",
    "\n",
    "test_data.drop('Transported', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f27ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ctc = ColumnTransformer([(\"imp\", SimpleImputer(strategy='most_frequent'), categorical_cols)])\n",
    "    \n",
    "train_data[categorical_cols] = ctc.fit_transform(train_data[categorical_cols])\n",
    "test_data[categorical_cols] = ctc.fit_transform(test_data[categorical_cols])\n",
    "\n",
    "ctn = ColumnTransformer([(\"imp\", SimpleImputer(strategy='median'), numeric_cols)])\n",
    "\n",
    "train_data[numeric_cols] = ctn.fit_transform(train_data[numeric_cols])\n",
    "test_data[numeric_cols] = ctn.fit_transform(test_data[numeric_cols])\n",
    "\n",
    "train_data[\"Transported\"].fillna(method='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c34987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f9586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
